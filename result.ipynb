{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-08T12:19:57.242013300Z",
     "start_time": "2023-12-08T12:19:57.235007500Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.utils import make_grid\n",
    "import argparse\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "from src.clustering_models.clusternet_modules.clusternetasmodel import ClusterNetModel\n",
    "from src.datasets import CustomDataset, STL10\n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "from sklearn.metrics import adjusted_rand_score as ARI\n",
    "from src.utils import cluster_acc\n",
    "\n",
    "def save_cluster_examples(args,predict,x_for_vis,\n",
    "                          labels,num_img,grid_size):\n",
    "    \n",
    "    def save_image(\n",
    "    tensor,\n",
    "    fp,\n",
    "    ) -> None:\n",
    "\n",
    "        grid = make_grid(tensor)\n",
    "        # Add 0.5 after unnormalizing to [0, 255] to round to nearest integer\n",
    "        ndarr = (grid.clamp_(0, 255).permute(1, 2, 0)\n",
    "                 .to(\"cpu\", torch.uint8).numpy())\n",
    "        im = Image.fromarray(ndarr)\n",
    "        im.save(fp)\n",
    "\n",
    "    if not os.path.exists(f\"./{args.dataset}_imgs/\"):\n",
    "        os.mkdir(f\"./{args.dataset}_imgs/\")\n",
    "    count=0\n",
    "    for k in np.unique(predict):\n",
    "        count+=1\n",
    "        x_k = x_for_vis[predict == k][:num_img]\n",
    "        y_gt = labels[predict == k][:num_img]\n",
    "        if not os.path.exists(f\"./{args.dataset}_imgs/{count}\"):\n",
    "            os.mkdir(f\"./{args.dataset}_imgs/{count}\")\n",
    "\n",
    "        for i in range(min(num_img, x_k.shape[0])):\n",
    "            save_image(x_k[i], f\"{args.dataset}_imgs/\"\n",
    "                               f\"{count}/clusternet_clus\"\n",
    "                               f\"{count}_label{y_gt[i]}_{i}.jpeg\")\n",
    "        # save as a grid\n",
    "        num_imgs = min(grid_size, x_k.shape[0])\n",
    "        if num_imgs > 0:\n",
    "            grid = make_grid(x_k[:num_imgs], nrow=num_imgs)\n",
    "            save_image(grid, f\"{args.dataset}_imgs/\"\n",
    "                             f\"{count}/clusternet_clus{count}.jpeg\")\n",
    "\n",
    "# LOAD MODEL FROM CHECKPOINT\n",
    "def fun():\n",
    "    cp_path = \"./saved_models/USPS/default_exp/epoch=699-step=51099.ckpt\" # E.g.: \"./saved_models/USPS/default_exp/epoch=499-step=36499.ckpt\"\n",
    "    cp_state = torch.load(cp_path)\n",
    "    data_dim =10 # E.g. for MNIST, it would be 10 if the network was trained on the embeedings supplied, or 28*28 otherwise.\n",
    "    K = cp_state['state_dict']['cluster_net.class_fc2.weight'].shape[0]\n",
    "    hyper_param = cp_state['hyper_parameters']\n",
    "    args = argparse.Namespace()\n",
    "    for key, value in hyper_param.items():\n",
    "        setattr(args, key, value)\n",
    "\n",
    "    model = ClusterNetModel.load_from_checkpoint(\n",
    "        checkpoint_path=cp_path,\n",
    "        input_dim=data_dim,\n",
    "        init_k = K,\n",
    "        hparams=args\n",
    "        )\n",
    "\n",
    "    # Example for inference :\n",
    "    model.eval()\n",
    "    dataset_obj = CustomDataset(args)\n",
    "\n",
    "    print(dataset_obj.data_dir)\n",
    "    print(model.K)\n",
    "\n",
    "\n",
    "    dataset = dataset_obj.get_train_data()\n",
    "    data = dataset.data\n",
    "    predict=  model(data).argmax(-1)\n",
    "    labels=dataset.targets.numpy()\n",
    "\n",
    "    acc = np.round(cluster_acc(labels, predict.numpy()), 5)\n",
    "    nmi = np.round(NMI(predict.numpy(), labels), 5)\n",
    "    ari = np.round(ARI(predict.numpy(), labels), 5)\n",
    "    print(f\"NMI: {nmi}, ARI: {ari}, acc: {acc}, final K: {len(np.unique(predict))}\")\n",
    "\n",
    "    print(np.unique(predict))\n",
    "\n",
    "\n",
    "    # num_img=20\n",
    "    # stl10=STL10(args)\n",
    "    # test_loader=stl10.get_test_loader()\n",
    "    # x_for_vis=torch.from_numpy(test_loader.dataset.data)\n",
    "    # \n",
    "    # save_cluster_examples(args,predict,x_for_vis,labels,num_img=20,grid_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential()\n",
      "./pretrained_embeddings/umap_embedded_datasets/USPS\n",
      "8\n",
      "NMI: 0.86441, ARI: 0.80714, acc: 0.80964, final K: 8\n",
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "fun()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T12:19:57.967669900Z",
     "start_time": "2023-12-08T12:19:57.884737800Z"
    }
   },
   "id": "e23d130caf40a566"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in pretrained_embeddings/MOCO/IMAGENET_50.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m transforms, datasets\n\u001B[0;32m      2\u001B[0m path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpretrained_embeddings/MOCO/IMAGENET_50\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 4\u001B[0m dataset\u001B[38;5;241m=\u001B[39m\u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mImageNet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompose\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mToTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNormalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# test=datasets.ImageNet(path, split=\"val\", download=True, transform=transforms.Compose([\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m#             transforms.ToTensor(),\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m#             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m#         ]))\u001B[39;00m\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\deepdpm3\\lib\\site-packages\\torchvision\\datasets\\imagenet.py:46\u001B[0m, in \u001B[0;36mImageNet.__init__\u001B[1;34m(self, root, split, **kwargs)\u001B[0m\n\u001B[0;32m     43\u001B[0m root \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexpanduser(root)\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msplit \u001B[38;5;241m=\u001B[39m verify_str_arg(split, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplit\u001B[39m\u001B[38;5;124m\"\u001B[39m, (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m---> 46\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_archives\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m wnid_to_classes \u001B[38;5;241m=\u001B[39m load_meta_file(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msplit_folder, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\deepdpm3\\lib\\site-packages\\torchvision\\datasets\\imagenet.py:59\u001B[0m, in \u001B[0;36mImageNet.parse_archives\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse_archives\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     58\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m check_integrity(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot, META_FILE)):\n\u001B[1;32m---> 59\u001B[0m         \u001B[43mparse_devkit_archive\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msplit_folder):\n\u001B[0;32m     62\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msplit \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\deepdpm3\\lib\\site-packages\\torchvision\\datasets\\imagenet.py:140\u001B[0m, in \u001B[0;36mparse_devkit_archive\u001B[1;34m(root, file)\u001B[0m\n\u001B[0;32m    137\u001B[0m     file \u001B[38;5;241m=\u001B[39m archive_meta[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    138\u001B[0m md5 \u001B[38;5;241m=\u001B[39m archive_meta[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m--> 140\u001B[0m \u001B[43m_verify_archive\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmd5\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_tmp_dir() \u001B[38;5;28;01mas\u001B[39;00m tmp_dir:\n\u001B[0;32m    143\u001B[0m     extract_archive(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(root, file), tmp_dir)\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\deepdpm3\\lib\\site-packages\\torchvision\\datasets\\imagenet.py:96\u001B[0m, in \u001B[0;36m_verify_archive\u001B[1;34m(root, file, md5)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m check_integrity(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(root, file), md5):\n\u001B[0;32m     92\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     93\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe archive \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m is not present in the root directory or is corrupted. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     94\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou need to download it externally and place it in \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     95\u001B[0m     )\n\u001B[1;32m---> 96\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg\u001B[38;5;241m.\u001B[39mformat(file, root))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in pretrained_embeddings/MOCO/IMAGENET_50."
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "path=\"pretrained_embeddings/MOCO/IMAGENET_50\"\n",
    "\n",
    "dataset=datasets.ImageNet(path, split=\"train\", download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ]))\n",
    "# test=datasets.ImageNet(path, split=\"val\", download=True, transform=transforms.Compose([\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#         ]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T11:46:45.226599700Z",
     "start_time": "2023-12-08T11:46:45.185601Z"
    }
   },
   "id": "cc90fec57e2fce44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f34be59d19e7565e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
